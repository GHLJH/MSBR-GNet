2022-11-02 14:36:41,366 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:36:41,366 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:36:41,367 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:36:44,219 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:36:44,220 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:36:44,221 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 3
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:36:44,223 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 3
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:36:44,223 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:36:47,132 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:36:47,133 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:44:06,559 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:44:06,607 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:44:06,607 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:44:09,489 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:44:09,490 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:44:09,491 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 3
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:44:09,493 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 3
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:44:09,493 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:44:12,400 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:44:12,400 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:44:12,689 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:44:12,691 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:44:12,696 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:45:11,302 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:45:11,359 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:45:11,359 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:45:14,330 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:45:14,331 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:45:14,332 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 3
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:45:14,334 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 3
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:45:14,335 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:45:17,246 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:45:17,247 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:45:17,512 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:45:17,663 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:45:17,668 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:47:08,158 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:47:08,220 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:47:08,220 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:47:11,369 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:47:11,370 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:47:11,371 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 3
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:47:11,372 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 3
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:47:11,373 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:47:14,209 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:47:14,209 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:47:14,477 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:47:14,532 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:47:14,536 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:48:32,358 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:48:32,438 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:48:32,439 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:48:35,359 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:48:35,359 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:48:35,361 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 2
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:48:35,363 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 2
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:48:35,363 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:48:38,451 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:48:38,452 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:48:38,720 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:48:38,775 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:48:38,780 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:48:53,372 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:48:53,421 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:48:53,422 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:48:56,274 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:48:56,275 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:48:56,276 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 4
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:48:56,278 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 4
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:48:56,279 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:48:59,267 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:48:59,267 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:48:59,532 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:48:59,587 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:48:59,592 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:49:14,144 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:49:14,158 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:49:14,159 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:49:17,044 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:49:17,044 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:49:17,046 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 1
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:49:17,048 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 1
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:49:17,048 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:49:20,013 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:49:20,013 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:49:20,281 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:49:20,455 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:49:20,459 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:51:07,380 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:51:07,391 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:51:07,391 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:51:10,328 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:51:10,328 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:51:10,329 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 1
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:51:10,331 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 1
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:51:10,331 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:51:13,215 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:51:13,215 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:51:13,487 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:51:13,660 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:51:13,665 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:51:39,995 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:51:40,027 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:51:40,027 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:51:42,958 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:51:42,958 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:51:42,959 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 3
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:51:42,961 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 3
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:51:42,962 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:51:45,836 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:51:45,837 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:51:46,125 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:51:46,188 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:51:46,194 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:54:22,440 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:54:22,464 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:54:22,464 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:54:25,488 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:54:25,488 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:54:25,489 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
#  WEIGHT:   " catalog://ImageNetPretrained/MSRA/R-101"                      #"/mnt/MSGAN/runs/build_coco/model_final.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN:  1000 # 2000
    FPN_POST_NMS_TOP_N_TRAIN:  4000   #8000
    PRE_NMS_TOP_N_TEST:     500         #1000
    POST_NMS_TOP_N_TEST:     500              #1000
    FPN_POST_NMS_TOP_N_TEST:   500               # 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 3
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS:    (100, 200)                      #(36000, 48000)
  MAX_ITER:      400   #54000
  IMS_PER_BATCH: 4
  TEST_PERIOD: 50          #2500
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:54:25,490 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 3
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 500
    FPN_POST_NMS_TOP_N_TRAIN: 4000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 500
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 500
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: 
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 400
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 50
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:54:25,491 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:54:28,332 maskrcnn_benchmark.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2022-11-02 14:54:28,333 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:54:28,600 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:54:28,691 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:54:28,695 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:57:27,658 maskrcnn_benchmark INFO: Using 1 GPUs
2022-11-02 14:57:27,701 maskrcnn_benchmark INFO: Namespace(config_file='/mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml', distributed=False, local_rank=0, opts=[], skip_test=False)
2022-11-02 14:57:27,702 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2022-11-02 14:57:30,610 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.10.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: Tesla K80
Nvidia driver version: 470.94
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip] numpy==1.16.0
[pip] torch==1.1.0
[pip] torchvision==0.3.0
[conda] mkl                       2019.0                   pypi_0    pypi
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.3.0                    pypi_0    pypi
        Pillow (6.1.0)
2022-11-02 14:57:30,611 maskrcnn_benchmark INFO: Loaded configuration file /mnt/MSGAN/maskrcnn-benchmark/configs/e2e_mask_rcnn_R_101_FPN_1x_phone.yaml
2022-11-02 14:57:30,612 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 8000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 3
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_cat_dog_train",)
  TEST: ("coco_cat_dog_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (100, 200)
  MAX_ITER: 200
  IMS_PER_BATCH: 4
  TEST_PERIOD: 100
INPUT:
  MIN_SIZE_TRAIN: (500, )
  MIN_SIZE_TEST: 500
OUTPUT_DIR:
  "runs/cat_dog_coco"
TEST:
  IMS_PER_BATCH: 4
2022-11-02 14:57:30,613 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('coco_cat_dog_val',)
  TRAIN: ('coco_cat_dog_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 500
  MIN_SIZE_TRAIN: (500,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 3
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 3
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 8000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 2000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-101
OUTPUT_DIR: runs/cat_dog_coco
PATHS_CATALOG: /mnt/MSGAN/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  MAX_ITER: 200
  MOMENTUM: 0.9
  STEPS: (100, 200)
  TEST_PERIOD: 100
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 4
2022-11-02 14:57:30,613 maskrcnn_benchmark INFO: Saving config into: runs/cat_dog_coco/config.yml
2022-11-02 14:57:33,487 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-101
2022-11-02 14:57:33,489 maskrcnn_benchmark.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-101 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl
2022-11-02 14:57:33,490 maskrcnn_benchmark.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl cached in /root/.torch/models/R-101.pkl
2022-11-02 14:57:33,612 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping C2 weights
2022-11-02 14:57:33,612 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_b               mapped name: conv1.bias
2022-11-02 14:57:33,613 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_w               mapped name: conv1.weight
2022-11-02 14:57:33,613 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_b              mapped name: fc1000.bias
2022-11-02 14:57:33,613 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_w              mapped name: fc1000.weight
2022-11-02 14:57:33,613 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b      mapped name: layer1.0.downsample.0.bias
2022-11-02 14:57:33,613 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b   mapped name: layer1.0.downsample.1.bias
2022-11-02 14:57:33,614 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s   mapped name: layer1.0.downsample.1.weight
2022-11-02 14:57:33,614 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w      mapped name: layer1.0.downsample.0.weight
2022-11-02 14:57:33,614 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b     mapped name: layer1.0.conv1.bias
2022-11-02 14:57:33,614 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b  mapped name: layer1.0.bn1.bias
2022-11-02 14:57:33,614 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s  mapped name: layer1.0.bn1.weight
2022-11-02 14:57:33,614 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w     mapped name: layer1.0.conv1.weight
2022-11-02 14:57:33,615 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b     mapped name: layer1.0.conv2.bias
2022-11-02 14:57:33,615 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b  mapped name: layer1.0.bn2.bias
2022-11-02 14:57:33,615 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s  mapped name: layer1.0.bn2.weight
2022-11-02 14:57:33,615 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w     mapped name: layer1.0.conv2.weight
2022-11-02 14:57:33,615 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b     mapped name: layer1.0.conv3.bias
2022-11-02 14:57:33,615 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b  mapped name: layer1.0.bn3.bias
2022-11-02 14:57:33,616 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s  mapped name: layer1.0.bn3.weight
2022-11-02 14:57:33,616 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w     mapped name: layer1.0.conv3.weight
2022-11-02 14:57:33,616 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b     mapped name: layer1.1.conv1.bias
2022-11-02 14:57:33,616 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b  mapped name: layer1.1.bn1.bias
2022-11-02 14:57:33,616 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s  mapped name: layer1.1.bn1.weight
2022-11-02 14:57:33,617 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w     mapped name: layer1.1.conv1.weight
2022-11-02 14:57:33,617 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b     mapped name: layer1.1.conv2.bias
2022-11-02 14:57:33,617 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b  mapped name: layer1.1.bn2.bias
2022-11-02 14:57:33,617 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s  mapped name: layer1.1.bn2.weight
2022-11-02 14:57:33,617 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w     mapped name: layer1.1.conv2.weight
2022-11-02 14:57:33,618 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b     mapped name: layer1.1.conv3.bias
2022-11-02 14:57:33,618 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b  mapped name: layer1.1.bn3.bias
2022-11-02 14:57:33,618 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s  mapped name: layer1.1.bn3.weight
2022-11-02 14:57:33,618 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w     mapped name: layer1.1.conv3.weight
2022-11-02 14:57:33,618 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b     mapped name: layer1.2.conv1.bias
2022-11-02 14:57:33,619 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b  mapped name: layer1.2.bn1.bias
2022-11-02 14:57:33,619 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s  mapped name: layer1.2.bn1.weight
2022-11-02 14:57:33,619 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w     mapped name: layer1.2.conv1.weight
2022-11-02 14:57:33,619 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b     mapped name: layer1.2.conv2.bias
2022-11-02 14:57:33,619 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b  mapped name: layer1.2.bn2.bias
2022-11-02 14:57:33,620 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s  mapped name: layer1.2.bn2.weight
2022-11-02 14:57:33,620 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w     mapped name: layer1.2.conv2.weight
2022-11-02 14:57:33,620 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b     mapped name: layer1.2.conv3.bias
2022-11-02 14:57:33,620 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b  mapped name: layer1.2.bn3.bias
2022-11-02 14:57:33,620 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s  mapped name: layer1.2.bn3.weight
2022-11-02 14:57:33,620 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w     mapped name: layer1.2.conv3.weight
2022-11-02 14:57:33,621 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b      mapped name: layer2.0.downsample.0.bias
2022-11-02 14:57:33,621 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b   mapped name: layer2.0.downsample.1.bias
2022-11-02 14:57:33,621 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s   mapped name: layer2.0.downsample.1.weight
2022-11-02 14:57:33,621 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w      mapped name: layer2.0.downsample.0.weight
2022-11-02 14:57:33,621 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b     mapped name: layer2.0.conv1.bias
2022-11-02 14:57:33,621 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b  mapped name: layer2.0.bn1.bias
2022-11-02 14:57:33,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s  mapped name: layer2.0.bn1.weight
2022-11-02 14:57:33,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w     mapped name: layer2.0.conv1.weight
2022-11-02 14:57:33,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b     mapped name: layer2.0.conv2.bias
2022-11-02 14:57:33,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b  mapped name: layer2.0.bn2.bias
2022-11-02 14:57:33,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s  mapped name: layer2.0.bn2.weight
2022-11-02 14:57:33,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w     mapped name: layer2.0.conv2.weight
2022-11-02 14:57:33,623 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b     mapped name: layer2.0.conv3.bias
2022-11-02 14:57:33,623 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b  mapped name: layer2.0.bn3.bias
2022-11-02 14:57:33,623 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s  mapped name: layer2.0.bn3.weight
2022-11-02 14:57:33,623 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w     mapped name: layer2.0.conv3.weight
2022-11-02 14:57:33,623 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b     mapped name: layer2.1.conv1.bias
2022-11-02 14:57:33,624 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b  mapped name: layer2.1.bn1.bias
2022-11-02 14:57:33,624 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s  mapped name: layer2.1.bn1.weight
2022-11-02 14:57:33,624 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w     mapped name: layer2.1.conv1.weight
2022-11-02 14:57:33,624 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b     mapped name: layer2.1.conv2.bias
2022-11-02 14:57:33,624 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b  mapped name: layer2.1.bn2.bias
2022-11-02 14:57:33,625 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s  mapped name: layer2.1.bn2.weight
2022-11-02 14:57:33,625 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w     mapped name: layer2.1.conv2.weight
2022-11-02 14:57:33,625 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b     mapped name: layer2.1.conv3.bias
2022-11-02 14:57:33,625 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b  mapped name: layer2.1.bn3.bias
2022-11-02 14:57:33,625 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s  mapped name: layer2.1.bn3.weight
2022-11-02 14:57:33,625 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w     mapped name: layer2.1.conv3.weight
2022-11-02 14:57:33,626 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b     mapped name: layer2.2.conv1.bias
2022-11-02 14:57:33,626 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b  mapped name: layer2.2.bn1.bias
2022-11-02 14:57:33,626 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s  mapped name: layer2.2.bn1.weight
2022-11-02 14:57:33,626 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w     mapped name: layer2.2.conv1.weight
2022-11-02 14:57:33,626 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b     mapped name: layer2.2.conv2.bias
2022-11-02 14:57:33,627 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b  mapped name: layer2.2.bn2.bias
2022-11-02 14:57:33,627 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s  mapped name: layer2.2.bn2.weight
2022-11-02 14:57:33,627 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w     mapped name: layer2.2.conv2.weight
2022-11-02 14:57:33,627 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b     mapped name: layer2.2.conv3.bias
2022-11-02 14:57:33,627 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b  mapped name: layer2.2.bn3.bias
2022-11-02 14:57:33,628 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s  mapped name: layer2.2.bn3.weight
2022-11-02 14:57:33,628 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w     mapped name: layer2.2.conv3.weight
2022-11-02 14:57:33,628 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b     mapped name: layer2.3.conv1.bias
2022-11-02 14:57:33,628 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b  mapped name: layer2.3.bn1.bias
2022-11-02 14:57:33,628 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s  mapped name: layer2.3.bn1.weight
2022-11-02 14:57:33,629 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w     mapped name: layer2.3.conv1.weight
2022-11-02 14:57:33,629 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b     mapped name: layer2.3.conv2.bias
2022-11-02 14:57:33,629 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b  mapped name: layer2.3.bn2.bias
2022-11-02 14:57:33,629 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s  mapped name: layer2.3.bn2.weight
2022-11-02 14:57:33,629 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w     mapped name: layer2.3.conv2.weight
2022-11-02 14:57:33,630 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b     mapped name: layer2.3.conv3.bias
2022-11-02 14:57:33,630 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b  mapped name: layer2.3.bn3.bias
2022-11-02 14:57:33,630 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s  mapped name: layer2.3.bn3.weight
2022-11-02 14:57:33,630 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w     mapped name: layer2.3.conv3.weight
2022-11-02 14:57:33,630 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b      mapped name: layer3.0.downsample.0.bias
2022-11-02 14:57:33,631 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b   mapped name: layer3.0.downsample.1.bias
2022-11-02 14:57:33,631 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s   mapped name: layer3.0.downsample.1.weight
2022-11-02 14:57:33,631 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w      mapped name: layer3.0.downsample.0.weight
2022-11-02 14:57:33,631 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b     mapped name: layer3.0.conv1.bias
2022-11-02 14:57:33,631 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b  mapped name: layer3.0.bn1.bias
2022-11-02 14:57:33,632 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s  mapped name: layer3.0.bn1.weight
2022-11-02 14:57:33,632 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w     mapped name: layer3.0.conv1.weight
2022-11-02 14:57:33,632 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b     mapped name: layer3.0.conv2.bias
2022-11-02 14:57:33,632 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b  mapped name: layer3.0.bn2.bias
2022-11-02 14:57:33,632 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s  mapped name: layer3.0.bn2.weight
2022-11-02 14:57:33,632 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w     mapped name: layer3.0.conv2.weight
2022-11-02 14:57:33,633 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b     mapped name: layer3.0.conv3.bias
2022-11-02 14:57:33,633 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b  mapped name: layer3.0.bn3.bias
2022-11-02 14:57:33,633 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s  mapped name: layer3.0.bn3.weight
2022-11-02 14:57:33,633 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w     mapped name: layer3.0.conv3.weight
2022-11-02 14:57:33,633 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_b    mapped name: layer3.10.conv1.bias
2022-11-02 14:57:33,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_b mapped name: layer3.10.bn1.bias
2022-11-02 14:57:33,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_s mapped name: layer3.10.bn1.weight
2022-11-02 14:57:33,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_w    mapped name: layer3.10.conv1.weight
2022-11-02 14:57:33,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_b    mapped name: layer3.10.conv2.bias
2022-11-02 14:57:33,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_b mapped name: layer3.10.bn2.bias
2022-11-02 14:57:33,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_s mapped name: layer3.10.bn2.weight
2022-11-02 14:57:33,635 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_w    mapped name: layer3.10.conv2.weight
2022-11-02 14:57:33,635 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_b    mapped name: layer3.10.conv3.bias
2022-11-02 14:57:33,635 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_b mapped name: layer3.10.bn3.bias
2022-11-02 14:57:33,635 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_s mapped name: layer3.10.bn3.weight
2022-11-02 14:57:33,635 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_w    mapped name: layer3.10.conv3.weight
2022-11-02 14:57:33,636 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_b    mapped name: layer3.11.conv1.bias
2022-11-02 14:57:33,636 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_b mapped name: layer3.11.bn1.bias
2022-11-02 14:57:33,636 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_s mapped name: layer3.11.bn1.weight
2022-11-02 14:57:33,636 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_w    mapped name: layer3.11.conv1.weight
2022-11-02 14:57:33,636 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_b    mapped name: layer3.11.conv2.bias
2022-11-02 14:57:33,637 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_b mapped name: layer3.11.bn2.bias
2022-11-02 14:57:33,637 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_s mapped name: layer3.11.bn2.weight
2022-11-02 14:57:33,637 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_w    mapped name: layer3.11.conv2.weight
2022-11-02 14:57:33,637 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_b    mapped name: layer3.11.conv3.bias
2022-11-02 14:57:33,637 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_b mapped name: layer3.11.bn3.bias
2022-11-02 14:57:33,637 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_s mapped name: layer3.11.bn3.weight
2022-11-02 14:57:33,638 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_w    mapped name: layer3.11.conv3.weight
2022-11-02 14:57:33,638 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_b    mapped name: layer3.12.conv1.bias
2022-11-02 14:57:33,638 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_b mapped name: layer3.12.bn1.bias
2022-11-02 14:57:33,638 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_s mapped name: layer3.12.bn1.weight
2022-11-02 14:57:33,638 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_w    mapped name: layer3.12.conv1.weight
2022-11-02 14:57:33,639 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_b    mapped name: layer3.12.conv2.bias
2022-11-02 14:57:33,639 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_b mapped name: layer3.12.bn2.bias
2022-11-02 14:57:33,639 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_s mapped name: layer3.12.bn2.weight
2022-11-02 14:57:33,639 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_w    mapped name: layer3.12.conv2.weight
2022-11-02 14:57:33,639 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_b    mapped name: layer3.12.conv3.bias
2022-11-02 14:57:33,639 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_b mapped name: layer3.12.bn3.bias
2022-11-02 14:57:33,640 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_s mapped name: layer3.12.bn3.weight
2022-11-02 14:57:33,640 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_w    mapped name: layer3.12.conv3.weight
2022-11-02 14:57:33,640 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_b    mapped name: layer3.13.conv1.bias
2022-11-02 14:57:33,640 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_b mapped name: layer3.13.bn1.bias
2022-11-02 14:57:33,640 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_s mapped name: layer3.13.bn1.weight
2022-11-02 14:57:33,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_w    mapped name: layer3.13.conv1.weight
2022-11-02 14:57:33,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_b    mapped name: layer3.13.conv2.bias
2022-11-02 14:57:33,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_b mapped name: layer3.13.bn2.bias
2022-11-02 14:57:33,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_s mapped name: layer3.13.bn2.weight
2022-11-02 14:57:33,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_w    mapped name: layer3.13.conv2.weight
2022-11-02 14:57:33,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_b    mapped name: layer3.13.conv3.bias
2022-11-02 14:57:33,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_b mapped name: layer3.13.bn3.bias
2022-11-02 14:57:33,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_s mapped name: layer3.13.bn3.weight
2022-11-02 14:57:33,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_w    mapped name: layer3.13.conv3.weight
2022-11-02 14:57:33,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_b    mapped name: layer3.14.conv1.bias
2022-11-02 14:57:33,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_b mapped name: layer3.14.bn1.bias
2022-11-02 14:57:33,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_s mapped name: layer3.14.bn1.weight
2022-11-02 14:57:33,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_w    mapped name: layer3.14.conv1.weight
2022-11-02 14:57:33,643 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_b    mapped name: layer3.14.conv2.bias
2022-11-02 14:57:33,643 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_b mapped name: layer3.14.bn2.bias
2022-11-02 14:57:33,643 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_s mapped name: layer3.14.bn2.weight
2022-11-02 14:57:33,643 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_w    mapped name: layer3.14.conv2.weight
2022-11-02 14:57:33,643 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_b    mapped name: layer3.14.conv3.bias
2022-11-02 14:57:33,644 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_b mapped name: layer3.14.bn3.bias
2022-11-02 14:57:33,644 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_s mapped name: layer3.14.bn3.weight
2022-11-02 14:57:33,644 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_w    mapped name: layer3.14.conv3.weight
2022-11-02 14:57:33,644 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_b    mapped name: layer3.15.conv1.bias
2022-11-02 14:57:33,644 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_b mapped name: layer3.15.bn1.bias
2022-11-02 14:57:33,644 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_s mapped name: layer3.15.bn1.weight
2022-11-02 14:57:33,645 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_w    mapped name: layer3.15.conv1.weight
2022-11-02 14:57:33,645 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_b    mapped name: layer3.15.conv2.bias
2022-11-02 14:57:33,645 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_b mapped name: layer3.15.bn2.bias
2022-11-02 14:57:33,645 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_s mapped name: layer3.15.bn2.weight
2022-11-02 14:57:33,645 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_w    mapped name: layer3.15.conv2.weight
2022-11-02 14:57:33,645 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_b    mapped name: layer3.15.conv3.bias
2022-11-02 14:57:33,646 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_b mapped name: layer3.15.bn3.bias
2022-11-02 14:57:33,646 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_s mapped name: layer3.15.bn3.weight
2022-11-02 14:57:33,646 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_w    mapped name: layer3.15.conv3.weight
2022-11-02 14:57:33,646 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_b    mapped name: layer3.16.conv1.bias
2022-11-02 14:57:33,646 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_b mapped name: layer3.16.bn1.bias
2022-11-02 14:57:33,646 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_s mapped name: layer3.16.bn1.weight
2022-11-02 14:57:33,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_w    mapped name: layer3.16.conv1.weight
2022-11-02 14:57:33,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_b    mapped name: layer3.16.conv2.bias
2022-11-02 14:57:33,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_b mapped name: layer3.16.bn2.bias
2022-11-02 14:57:33,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_s mapped name: layer3.16.bn2.weight
2022-11-02 14:57:33,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_w    mapped name: layer3.16.conv2.weight
2022-11-02 14:57:33,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_b    mapped name: layer3.16.conv3.bias
2022-11-02 14:57:33,648 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_b mapped name: layer3.16.bn3.bias
2022-11-02 14:57:33,648 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_s mapped name: layer3.16.bn3.weight
2022-11-02 14:57:33,648 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_w    mapped name: layer3.16.conv3.weight
2022-11-02 14:57:33,648 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_b    mapped name: layer3.17.conv1.bias
2022-11-02 14:57:33,648 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_b mapped name: layer3.17.bn1.bias
2022-11-02 14:57:33,648 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_s mapped name: layer3.17.bn1.weight
2022-11-02 14:57:33,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_w    mapped name: layer3.17.conv1.weight
2022-11-02 14:57:33,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_b    mapped name: layer3.17.conv2.bias
2022-11-02 14:57:33,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_b mapped name: layer3.17.bn2.bias
2022-11-02 14:57:33,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_s mapped name: layer3.17.bn2.weight
2022-11-02 14:57:33,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_w    mapped name: layer3.17.conv2.weight
2022-11-02 14:57:33,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_b    mapped name: layer3.17.conv3.bias
2022-11-02 14:57:33,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_b mapped name: layer3.17.bn3.bias
2022-11-02 14:57:33,650 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_s mapped name: layer3.17.bn3.weight
2022-11-02 14:57:33,650 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_w    mapped name: layer3.17.conv3.weight
2022-11-02 14:57:33,650 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_b    mapped name: layer3.18.conv1.bias
2022-11-02 14:57:33,650 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_b mapped name: layer3.18.bn1.bias
2022-11-02 14:57:33,650 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_s mapped name: layer3.18.bn1.weight
2022-11-02 14:57:33,650 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_w    mapped name: layer3.18.conv1.weight
2022-11-02 14:57:33,651 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_b    mapped name: layer3.18.conv2.bias
2022-11-02 14:57:33,651 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_b mapped name: layer3.18.bn2.bias
2022-11-02 14:57:33,651 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_s mapped name: layer3.18.bn2.weight
2022-11-02 14:57:33,651 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_w    mapped name: layer3.18.conv2.weight
2022-11-02 14:57:33,651 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_b    mapped name: layer3.18.conv3.bias
2022-11-02 14:57:33,652 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_b mapped name: layer3.18.bn3.bias
2022-11-02 14:57:33,652 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_s mapped name: layer3.18.bn3.weight
2022-11-02 14:57:33,652 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_w    mapped name: layer3.18.conv3.weight
2022-11-02 14:57:33,652 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_b    mapped name: layer3.19.conv1.bias
2022-11-02 14:57:33,652 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_b mapped name: layer3.19.bn1.bias
2022-11-02 14:57:33,652 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_s mapped name: layer3.19.bn1.weight
2022-11-02 14:57:33,653 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_w    mapped name: layer3.19.conv1.weight
2022-11-02 14:57:33,653 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_b    mapped name: layer3.19.conv2.bias
2022-11-02 14:57:33,653 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_b mapped name: layer3.19.bn2.bias
2022-11-02 14:57:33,653 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_s mapped name: layer3.19.bn2.weight
2022-11-02 14:57:33,653 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_w    mapped name: layer3.19.conv2.weight
2022-11-02 14:57:33,654 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_b    mapped name: layer3.19.conv3.bias
2022-11-02 14:57:33,654 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_b mapped name: layer3.19.bn3.bias
2022-11-02 14:57:33,654 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_s mapped name: layer3.19.bn3.weight
2022-11-02 14:57:33,654 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_w    mapped name: layer3.19.conv3.weight
2022-11-02 14:57:33,654 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b     mapped name: layer3.1.conv1.bias
2022-11-02 14:57:33,654 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b  mapped name: layer3.1.bn1.bias
2022-11-02 14:57:33,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s  mapped name: layer3.1.bn1.weight
2022-11-02 14:57:33,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w     mapped name: layer3.1.conv1.weight
2022-11-02 14:57:33,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b     mapped name: layer3.1.conv2.bias
2022-11-02 14:57:33,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b  mapped name: layer3.1.bn2.bias
2022-11-02 14:57:33,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s  mapped name: layer3.1.bn2.weight
2022-11-02 14:57:33,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w     mapped name: layer3.1.conv2.weight
2022-11-02 14:57:33,656 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b     mapped name: layer3.1.conv3.bias
2022-11-02 14:57:33,656 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b  mapped name: layer3.1.bn3.bias
2022-11-02 14:57:33,656 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s  mapped name: layer3.1.bn3.weight
2022-11-02 14:57:33,656 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w     mapped name: layer3.1.conv3.weight
2022-11-02 14:57:33,656 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_b    mapped name: layer3.20.conv1.bias
2022-11-02 14:57:33,656 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_b mapped name: layer3.20.bn1.bias
2022-11-02 14:57:33,657 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_s mapped name: layer3.20.bn1.weight
2022-11-02 14:57:33,657 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_w    mapped name: layer3.20.conv1.weight
2022-11-02 14:57:33,657 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_b    mapped name: layer3.20.conv2.bias
2022-11-02 14:57:33,657 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_b mapped name: layer3.20.bn2.bias
2022-11-02 14:57:33,657 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_s mapped name: layer3.20.bn2.weight
2022-11-02 14:57:33,657 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_w    mapped name: layer3.20.conv2.weight
2022-11-02 14:57:33,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_b    mapped name: layer3.20.conv3.bias
2022-11-02 14:57:33,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_b mapped name: layer3.20.bn3.bias
2022-11-02 14:57:33,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_s mapped name: layer3.20.bn3.weight
2022-11-02 14:57:33,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_w    mapped name: layer3.20.conv3.weight
2022-11-02 14:57:33,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_b    mapped name: layer3.21.conv1.bias
2022-11-02 14:57:33,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_b mapped name: layer3.21.bn1.bias
2022-11-02 14:57:33,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_s mapped name: layer3.21.bn1.weight
2022-11-02 14:57:33,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_w    mapped name: layer3.21.conv1.weight
2022-11-02 14:57:33,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_b    mapped name: layer3.21.conv2.bias
2022-11-02 14:57:33,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_b mapped name: layer3.21.bn2.bias
2022-11-02 14:57:33,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_s mapped name: layer3.21.bn2.weight
2022-11-02 14:57:33,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_w    mapped name: layer3.21.conv2.weight
2022-11-02 14:57:33,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_b    mapped name: layer3.21.conv3.bias
2022-11-02 14:57:33,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_b mapped name: layer3.21.bn3.bias
2022-11-02 14:57:33,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_s mapped name: layer3.21.bn3.weight
2022-11-02 14:57:33,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_w    mapped name: layer3.21.conv3.weight
2022-11-02 14:57:33,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_b    mapped name: layer3.22.conv1.bias
2022-11-02 14:57:33,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_b mapped name: layer3.22.bn1.bias
2022-11-02 14:57:33,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_s mapped name: layer3.22.bn1.weight
2022-11-02 14:57:33,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_w    mapped name: layer3.22.conv1.weight
2022-11-02 14:57:33,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_b    mapped name: layer3.22.conv2.bias
2022-11-02 14:57:33,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_b mapped name: layer3.22.bn2.bias
2022-11-02 14:57:33,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_s mapped name: layer3.22.bn2.weight
2022-11-02 14:57:33,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_w    mapped name: layer3.22.conv2.weight
2022-11-02 14:57:33,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_b    mapped name: layer3.22.conv3.bias
2022-11-02 14:57:33,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_b mapped name: layer3.22.bn3.bias
2022-11-02 14:57:33,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_s mapped name: layer3.22.bn3.weight
2022-11-02 14:57:33,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_w    mapped name: layer3.22.conv3.weight
2022-11-02 14:57:33,662 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b     mapped name: layer3.2.conv1.bias
2022-11-02 14:57:33,662 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b  mapped name: layer3.2.bn1.bias
2022-11-02 14:57:33,662 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s  mapped name: layer3.2.bn1.weight
2022-11-02 14:57:33,662 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w     mapped name: layer3.2.conv1.weight
2022-11-02 14:57:33,662 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b     mapped name: layer3.2.conv2.bias
2022-11-02 14:57:33,662 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b  mapped name: layer3.2.bn2.bias
2022-11-02 14:57:33,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s  mapped name: layer3.2.bn2.weight
2022-11-02 14:57:33,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w     mapped name: layer3.2.conv2.weight
2022-11-02 14:57:33,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b     mapped name: layer3.2.conv3.bias
2022-11-02 14:57:33,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b  mapped name: layer3.2.bn3.bias
2022-11-02 14:57:33,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s  mapped name: layer3.2.bn3.weight
2022-11-02 14:57:33,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w     mapped name: layer3.2.conv3.weight
2022-11-02 14:57:33,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b     mapped name: layer3.3.conv1.bias
2022-11-02 14:57:33,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b  mapped name: layer3.3.bn1.bias
2022-11-02 14:57:33,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s  mapped name: layer3.3.bn1.weight
2022-11-02 14:57:33,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w     mapped name: layer3.3.conv1.weight
2022-11-02 14:57:33,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b     mapped name: layer3.3.conv2.bias
2022-11-02 14:57:33,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b  mapped name: layer3.3.bn2.bias
2022-11-02 14:57:33,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s  mapped name: layer3.3.bn2.weight
2022-11-02 14:57:33,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w     mapped name: layer3.3.conv2.weight
2022-11-02 14:57:33,665 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b     mapped name: layer3.3.conv3.bias
2022-11-02 14:57:33,665 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b  mapped name: layer3.3.bn3.bias
2022-11-02 14:57:33,665 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s  mapped name: layer3.3.bn3.weight
2022-11-02 14:57:33,665 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w     mapped name: layer3.3.conv3.weight
2022-11-02 14:57:33,665 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b     mapped name: layer3.4.conv1.bias
2022-11-02 14:57:33,665 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b  mapped name: layer3.4.bn1.bias
2022-11-02 14:57:33,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s  mapped name: layer3.4.bn1.weight
2022-11-02 14:57:33,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w     mapped name: layer3.4.conv1.weight
2022-11-02 14:57:33,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b     mapped name: layer3.4.conv2.bias
2022-11-02 14:57:33,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b  mapped name: layer3.4.bn2.bias
2022-11-02 14:57:33,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s  mapped name: layer3.4.bn2.weight
2022-11-02 14:57:33,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w     mapped name: layer3.4.conv2.weight
2022-11-02 14:57:33,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b     mapped name: layer3.4.conv3.bias
2022-11-02 14:57:33,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b  mapped name: layer3.4.bn3.bias
2022-11-02 14:57:33,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s  mapped name: layer3.4.bn3.weight
2022-11-02 14:57:33,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w     mapped name: layer3.4.conv3.weight
2022-11-02 14:57:33,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b     mapped name: layer3.5.conv1.bias
2022-11-02 14:57:33,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b  mapped name: layer3.5.bn1.bias
2022-11-02 14:57:33,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s  mapped name: layer3.5.bn1.weight
2022-11-02 14:57:33,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w     mapped name: layer3.5.conv1.weight
2022-11-02 14:57:33,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b     mapped name: layer3.5.conv2.bias
2022-11-02 14:57:33,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b  mapped name: layer3.5.bn2.bias
2022-11-02 14:57:33,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s  mapped name: layer3.5.bn2.weight
2022-11-02 14:57:33,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w     mapped name: layer3.5.conv2.weight
2022-11-02 14:57:33,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b     mapped name: layer3.5.conv3.bias
2022-11-02 14:57:33,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b  mapped name: layer3.5.bn3.bias
2022-11-02 14:57:33,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s  mapped name: layer3.5.bn3.weight
2022-11-02 14:57:33,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w     mapped name: layer3.5.conv3.weight
2022-11-02 14:57:33,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_b     mapped name: layer3.6.conv1.bias
2022-11-02 14:57:33,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_b  mapped name: layer3.6.bn1.bias
2022-11-02 14:57:33,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_s  mapped name: layer3.6.bn1.weight
2022-11-02 14:57:33,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_w     mapped name: layer3.6.conv1.weight
2022-11-02 14:57:33,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_b     mapped name: layer3.6.conv2.bias
2022-11-02 14:57:33,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_b  mapped name: layer3.6.bn2.bias
2022-11-02 14:57:33,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_s  mapped name: layer3.6.bn2.weight
2022-11-02 14:57:33,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_w     mapped name: layer3.6.conv2.weight
2022-11-02 14:57:33,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_b     mapped name: layer3.6.conv3.bias
2022-11-02 14:57:33,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_b  mapped name: layer3.6.bn3.bias
2022-11-02 14:57:33,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_s  mapped name: layer3.6.bn3.weight
2022-11-02 14:57:33,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_w     mapped name: layer3.6.conv3.weight
2022-11-02 14:57:33,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_b     mapped name: layer3.7.conv1.bias
2022-11-02 14:57:33,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_b  mapped name: layer3.7.bn1.bias
2022-11-02 14:57:33,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_s  mapped name: layer3.7.bn1.weight
2022-11-02 14:57:33,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_w     mapped name: layer3.7.conv1.weight
2022-11-02 14:57:33,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_b     mapped name: layer3.7.conv2.bias
2022-11-02 14:57:33,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_b  mapped name: layer3.7.bn2.bias
2022-11-02 14:57:33,672 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_s  mapped name: layer3.7.bn2.weight
2022-11-02 14:57:33,672 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_w     mapped name: layer3.7.conv2.weight
2022-11-02 14:57:33,672 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_b     mapped name: layer3.7.conv3.bias
2022-11-02 14:57:33,672 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_b  mapped name: layer3.7.bn3.bias
2022-11-02 14:57:33,672 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_s  mapped name: layer3.7.bn3.weight
2022-11-02 14:57:33,672 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_w     mapped name: layer3.7.conv3.weight
2022-11-02 14:57:33,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_b     mapped name: layer3.8.conv1.bias
2022-11-02 14:57:33,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_b  mapped name: layer3.8.bn1.bias
2022-11-02 14:57:33,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_s  mapped name: layer3.8.bn1.weight
2022-11-02 14:57:33,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_w     mapped name: layer3.8.conv1.weight
2022-11-02 14:57:33,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_b     mapped name: layer3.8.conv2.bias
2022-11-02 14:57:33,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_b  mapped name: layer3.8.bn2.bias
2022-11-02 14:57:33,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_s  mapped name: layer3.8.bn2.weight
2022-11-02 14:57:33,674 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_w     mapped name: layer3.8.conv2.weight
2022-11-02 14:57:33,674 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_b     mapped name: layer3.8.conv3.bias
2022-11-02 14:57:33,674 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_b  mapped name: layer3.8.bn3.bias
2022-11-02 14:57:33,674 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_s  mapped name: layer3.8.bn3.weight
2022-11-02 14:57:33,674 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_w     mapped name: layer3.8.conv3.weight
2022-11-02 14:57:33,675 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_b     mapped name: layer3.9.conv1.bias
2022-11-02 14:57:33,675 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_b  mapped name: layer3.9.bn1.bias
2022-11-02 14:57:33,675 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_s  mapped name: layer3.9.bn1.weight
2022-11-02 14:57:33,675 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_w     mapped name: layer3.9.conv1.weight
2022-11-02 14:57:33,675 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_b     mapped name: layer3.9.conv2.bias
2022-11-02 14:57:33,676 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_b  mapped name: layer3.9.bn2.bias
2022-11-02 14:57:33,676 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_s  mapped name: layer3.9.bn2.weight
2022-11-02 14:57:33,676 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_w     mapped name: layer3.9.conv2.weight
2022-11-02 14:57:33,676 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_b     mapped name: layer3.9.conv3.bias
2022-11-02 14:57:33,676 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_b  mapped name: layer3.9.bn3.bias
2022-11-02 14:57:33,676 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_s  mapped name: layer3.9.bn3.weight
2022-11-02 14:57:33,676 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_w     mapped name: layer3.9.conv3.weight
2022-11-02 14:57:33,677 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b      mapped name: layer4.0.downsample.0.bias
2022-11-02 14:57:33,677 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b   mapped name: layer4.0.downsample.1.bias
2022-11-02 14:57:33,677 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s   mapped name: layer4.0.downsample.1.weight
2022-11-02 14:57:33,677 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w      mapped name: layer4.0.downsample.0.weight
2022-11-02 14:57:33,677 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b     mapped name: layer4.0.conv1.bias
2022-11-02 14:57:33,677 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b  mapped name: layer4.0.bn1.bias
2022-11-02 14:57:33,678 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s  mapped name: layer4.0.bn1.weight
2022-11-02 14:57:33,678 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w     mapped name: layer4.0.conv1.weight
2022-11-02 14:57:33,678 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b     mapped name: layer4.0.conv2.bias
2022-11-02 14:57:33,678 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b  mapped name: layer4.0.bn2.bias
2022-11-02 14:57:33,678 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s  mapped name: layer4.0.bn2.weight
2022-11-02 14:57:33,678 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w     mapped name: layer4.0.conv2.weight
2022-11-02 14:57:33,679 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b     mapped name: layer4.0.conv3.bias
2022-11-02 14:57:33,679 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b  mapped name: layer4.0.bn3.bias
2022-11-02 14:57:33,679 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s  mapped name: layer4.0.bn3.weight
2022-11-02 14:57:33,679 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w     mapped name: layer4.0.conv3.weight
2022-11-02 14:57:33,679 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b     mapped name: layer4.1.conv1.bias
2022-11-02 14:57:33,680 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b  mapped name: layer4.1.bn1.bias
2022-11-02 14:57:33,680 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s  mapped name: layer4.1.bn1.weight
2022-11-02 14:57:33,680 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w     mapped name: layer4.1.conv1.weight
2022-11-02 14:57:33,680 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b     mapped name: layer4.1.conv2.bias
2022-11-02 14:57:33,680 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b  mapped name: layer4.1.bn2.bias
2022-11-02 14:57:33,680 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s  mapped name: layer4.1.bn2.weight
2022-11-02 14:57:33,681 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w     mapped name: layer4.1.conv2.weight
2022-11-02 14:57:33,681 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b     mapped name: layer4.1.conv3.bias
2022-11-02 14:57:33,681 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b  mapped name: layer4.1.bn3.bias
2022-11-02 14:57:33,681 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s  mapped name: layer4.1.bn3.weight
2022-11-02 14:57:33,681 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w     mapped name: layer4.1.conv3.weight
2022-11-02 14:57:33,681 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b     mapped name: layer4.2.conv1.bias
2022-11-02 14:57:33,682 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b  mapped name: layer4.2.bn1.bias
2022-11-02 14:57:33,682 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s  mapped name: layer4.2.bn1.weight
2022-11-02 14:57:33,682 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w     mapped name: layer4.2.conv1.weight
2022-11-02 14:57:33,682 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b     mapped name: layer4.2.conv2.bias
2022-11-02 14:57:33,682 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b  mapped name: layer4.2.bn2.bias
2022-11-02 14:57:33,683 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s  mapped name: layer4.2.bn2.weight
2022-11-02 14:57:33,683 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w     mapped name: layer4.2.conv2.weight
2022-11-02 14:57:33,683 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b     mapped name: layer4.2.conv3.bias
2022-11-02 14:57:33,683 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b  mapped name: layer4.2.bn3.bias
2022-11-02 14:57:33,683 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s  mapped name: layer4.2.bn3.weight
2022-11-02 14:57:33,684 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w     mapped name: layer4.2.conv3.weight
2022-11-02 14:57:33,684 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b        mapped name: bn1.bias
2022-11-02 14:57:33,684 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s        mapped name: bn1.weight
2022-11-02 14:57:33,684 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights
2022-11-02 14:57:33,844 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                   loaded from layer1.0.bn1.bias            of shape (64,)
2022-11-02 14:57:33,844 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                 loaded from layer1.0.bn1.weight          of shape (64,)
2022-11-02 14:57:33,845 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                   loaded from layer1.0.bn2.bias            of shape (64,)
2022-11-02 14:57:33,845 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                 loaded from layer1.0.bn2.weight          of shape (64,)
2022-11-02 14:57:33,845 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                   loaded from layer1.0.bn3.bias            of shape (256,)
2022-11-02 14:57:33,845 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                 loaded from layer1.0.bn3.weight          of shape (256,)
2022-11-02 14:57:33,845 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight               loaded from layer1.0.conv1.weight        of shape (64, 64, 1, 1)
2022-11-02 14:57:33,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight               loaded from layer1.0.conv2.weight        of shape (64, 64, 3, 3)
2022-11-02 14:57:33,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight               loaded from layer1.0.conv3.weight        of shape (256, 64, 1, 1)
2022-11-02 14:57:33,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight        loaded from layer1.0.downsample.0.weight of shape (256, 64, 1, 1)
2022-11-02 14:57:33,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias          loaded from layer1.0.downsample.1.bias   of shape (256,)
2022-11-02 14:57:33,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight        loaded from layer1.0.downsample.1.weight of shape (256,)
2022-11-02 14:57:33,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                   loaded from layer1.1.bn1.bias            of shape (64,)
2022-11-02 14:57:33,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                 loaded from layer1.1.bn1.weight          of shape (64,)
2022-11-02 14:57:33,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                   loaded from layer1.1.bn2.bias            of shape (64,)
2022-11-02 14:57:33,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                 loaded from layer1.1.bn2.weight          of shape (64,)
2022-11-02 14:57:33,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                   loaded from layer1.1.bn3.bias            of shape (256,)
2022-11-02 14:57:33,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                 loaded from layer1.1.bn3.weight          of shape (256,)
2022-11-02 14:57:33,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight               loaded from layer1.1.conv1.weight        of shape (64, 256, 1, 1)
2022-11-02 14:57:33,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight               loaded from layer1.1.conv2.weight        of shape (64, 64, 3, 3)
2022-11-02 14:57:33,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight               loaded from layer1.1.conv3.weight        of shape (256, 64, 1, 1)
2022-11-02 14:57:33,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                   loaded from layer1.2.bn1.bias            of shape (64,)
2022-11-02 14:57:33,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                 loaded from layer1.2.bn1.weight          of shape (64,)
2022-11-02 14:57:33,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                   loaded from layer1.2.bn2.bias            of shape (64,)
2022-11-02 14:57:33,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                 loaded from layer1.2.bn2.weight          of shape (64,)
2022-11-02 14:57:33,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                   loaded from layer1.2.bn3.bias            of shape (256,)
2022-11-02 14:57:33,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                 loaded from layer1.2.bn3.weight          of shape (256,)
2022-11-02 14:57:33,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight               loaded from layer1.2.conv1.weight        of shape (64, 256, 1, 1)
2022-11-02 14:57:33,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight               loaded from layer1.2.conv2.weight        of shape (64, 64, 3, 3)
2022-11-02 14:57:33,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight               loaded from layer1.2.conv3.weight        of shape (256, 64, 1, 1)
2022-11-02 14:57:33,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                   loaded from layer2.0.bn1.bias            of shape (128,)
2022-11-02 14:57:33,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                 loaded from layer2.0.bn1.weight          of shape (128,)
2022-11-02 14:57:33,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                   loaded from layer2.0.bn2.bias            of shape (128,)
2022-11-02 14:57:33,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                 loaded from layer2.0.bn2.weight          of shape (128,)
2022-11-02 14:57:33,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                   loaded from layer2.0.bn3.bias            of shape (512,)
2022-11-02 14:57:33,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                 loaded from layer2.0.bn3.weight          of shape (512,)
2022-11-02 14:57:33,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight               loaded from layer2.0.conv1.weight        of shape (128, 256, 1, 1)
2022-11-02 14:57:33,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight               loaded from layer2.0.conv2.weight        of shape (128, 128, 3, 3)
2022-11-02 14:57:33,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight               loaded from layer2.0.conv3.weight        of shape (512, 128, 1, 1)
2022-11-02 14:57:33,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight        loaded from layer2.0.downsample.0.weight of shape (512, 256, 1, 1)
2022-11-02 14:57:33,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias          loaded from layer2.0.downsample.1.bias   of shape (512,)
2022-11-02 14:57:33,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight        loaded from layer2.0.downsample.1.weight of shape (512,)
2022-11-02 14:57:33,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                   loaded from layer2.1.bn1.bias            of shape (128,)
2022-11-02 14:57:33,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                 loaded from layer2.1.bn1.weight          of shape (128,)
2022-11-02 14:57:33,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                   loaded from layer2.1.bn2.bias            of shape (128,)
2022-11-02 14:57:33,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                 loaded from layer2.1.bn2.weight          of shape (128,)
2022-11-02 14:57:33,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                   loaded from layer2.1.bn3.bias            of shape (512,)
2022-11-02 14:57:33,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                 loaded from layer2.1.bn3.weight          of shape (512,)
2022-11-02 14:57:33,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight               loaded from layer2.1.conv1.weight        of shape (128, 512, 1, 1)
2022-11-02 14:57:33,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight               loaded from layer2.1.conv2.weight        of shape (128, 128, 3, 3)
2022-11-02 14:57:33,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight               loaded from layer2.1.conv3.weight        of shape (512, 128, 1, 1)
2022-11-02 14:57:33,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                   loaded from layer2.2.bn1.bias            of shape (128,)
2022-11-02 14:57:33,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                 loaded from layer2.2.bn1.weight          of shape (128,)
2022-11-02 14:57:33,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                   loaded from layer2.2.bn2.bias            of shape (128,)
2022-11-02 14:57:33,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                 loaded from layer2.2.bn2.weight          of shape (128,)
2022-11-02 14:57:33,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                   loaded from layer2.2.bn3.bias            of shape (512,)
2022-11-02 14:57:33,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                 loaded from layer2.2.bn3.weight          of shape (512,)
2022-11-02 14:57:33,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight               loaded from layer2.2.conv1.weight        of shape (128, 512, 1, 1)
2022-11-02 14:57:33,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight               loaded from layer2.2.conv2.weight        of shape (128, 128, 3, 3)
2022-11-02 14:57:33,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight               loaded from layer2.2.conv3.weight        of shape (512, 128, 1, 1)
2022-11-02 14:57:33,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                   loaded from layer2.3.bn1.bias            of shape (128,)
2022-11-02 14:57:33,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                 loaded from layer2.3.bn1.weight          of shape (128,)
2022-11-02 14:57:33,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                   loaded from layer2.3.bn2.bias            of shape (128,)
2022-11-02 14:57:33,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                 loaded from layer2.3.bn2.weight          of shape (128,)
2022-11-02 14:57:33,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                   loaded from layer2.3.bn3.bias            of shape (512,)
2022-11-02 14:57:33,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                 loaded from layer2.3.bn3.weight          of shape (512,)
2022-11-02 14:57:33,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight               loaded from layer2.3.conv1.weight        of shape (128, 512, 1, 1)
2022-11-02 14:57:33,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight               loaded from layer2.3.conv2.weight        of shape (128, 128, 3, 3)
2022-11-02 14:57:33,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight               loaded from layer2.3.conv3.weight        of shape (512, 128, 1, 1)
2022-11-02 14:57:33,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                   loaded from layer3.0.bn1.bias            of shape (256,)
2022-11-02 14:57:33,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                 loaded from layer3.0.bn1.weight          of shape (256,)
2022-11-02 14:57:33,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                   loaded from layer3.0.bn2.bias            of shape (256,)
2022-11-02 14:57:33,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                 loaded from layer3.0.bn2.weight          of shape (256,)
2022-11-02 14:57:33,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                   loaded from layer3.0.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                 loaded from layer3.0.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight               loaded from layer3.0.conv1.weight        of shape (256, 512, 1, 1)
2022-11-02 14:57:33,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight               loaded from layer3.0.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight               loaded from layer3.0.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight        loaded from layer3.0.downsample.0.weight of shape (1024, 512, 1, 1)
2022-11-02 14:57:33,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias          loaded from layer3.0.downsample.1.bias   of shape (1024,)
2022-11-02 14:57:33,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight        loaded from layer3.0.downsample.1.weight of shape (1024,)
2022-11-02 14:57:33,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                   loaded from layer3.1.bn1.bias            of shape (256,)
2022-11-02 14:57:33,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                 loaded from layer3.1.bn1.weight          of shape (256,)
2022-11-02 14:57:33,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                   loaded from layer3.1.bn2.bias            of shape (256,)
2022-11-02 14:57:33,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                 loaded from layer3.1.bn2.weight          of shape (256,)
2022-11-02 14:57:33,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                   loaded from layer3.1.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                 loaded from layer3.1.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight               loaded from layer3.1.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight               loaded from layer3.1.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight               loaded from layer3.1.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                  loaded from layer3.10.bn1.bias           of shape (256,)
2022-11-02 14:57:33,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight                loaded from layer3.10.bn1.weight         of shape (256,)
2022-11-02 14:57:33,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                  loaded from layer3.10.bn2.bias           of shape (256,)
2022-11-02 14:57:33,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight                loaded from layer3.10.bn2.weight         of shape (256,)
2022-11-02 14:57:33,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                  loaded from layer3.10.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight                loaded from layer3.10.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight              loaded from layer3.10.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight              loaded from layer3.10.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight              loaded from layer3.10.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                  loaded from layer3.11.bn1.bias           of shape (256,)
2022-11-02 14:57:33,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight                loaded from layer3.11.bn1.weight         of shape (256,)
2022-11-02 14:57:33,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                  loaded from layer3.11.bn2.bias           of shape (256,)
2022-11-02 14:57:33,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight                loaded from layer3.11.bn2.weight         of shape (256,)
2022-11-02 14:57:33,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                  loaded from layer3.11.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight                loaded from layer3.11.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight              loaded from layer3.11.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight              loaded from layer3.11.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight              loaded from layer3.11.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                  loaded from layer3.12.bn1.bias           of shape (256,)
2022-11-02 14:57:33,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight                loaded from layer3.12.bn1.weight         of shape (256,)
2022-11-02 14:57:33,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                  loaded from layer3.12.bn2.bias           of shape (256,)
2022-11-02 14:57:33,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight                loaded from layer3.12.bn2.weight         of shape (256,)
2022-11-02 14:57:33,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                  loaded from layer3.12.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight                loaded from layer3.12.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight              loaded from layer3.12.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight              loaded from layer3.12.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight              loaded from layer3.12.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                  loaded from layer3.13.bn1.bias           of shape (256,)
2022-11-02 14:57:33,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight                loaded from layer3.13.bn1.weight         of shape (256,)
2022-11-02 14:57:33,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                  loaded from layer3.13.bn2.bias           of shape (256,)
2022-11-02 14:57:33,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight                loaded from layer3.13.bn2.weight         of shape (256,)
2022-11-02 14:57:33,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                  loaded from layer3.13.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight                loaded from layer3.13.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight              loaded from layer3.13.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight              loaded from layer3.13.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight              loaded from layer3.13.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                  loaded from layer3.14.bn1.bias           of shape (256,)
2022-11-02 14:57:33,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight                loaded from layer3.14.bn1.weight         of shape (256,)
2022-11-02 14:57:33,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                  loaded from layer3.14.bn2.bias           of shape (256,)
2022-11-02 14:57:33,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight                loaded from layer3.14.bn2.weight         of shape (256,)
2022-11-02 14:57:33,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                  loaded from layer3.14.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight                loaded from layer3.14.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight              loaded from layer3.14.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight              loaded from layer3.14.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight              loaded from layer3.14.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                  loaded from layer3.15.bn1.bias           of shape (256,)
2022-11-02 14:57:33,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight                loaded from layer3.15.bn1.weight         of shape (256,)
2022-11-02 14:57:33,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                  loaded from layer3.15.bn2.bias           of shape (256,)
2022-11-02 14:57:33,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight                loaded from layer3.15.bn2.weight         of shape (256,)
2022-11-02 14:57:33,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                  loaded from layer3.15.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight                loaded from layer3.15.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight              loaded from layer3.15.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight              loaded from layer3.15.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight              loaded from layer3.15.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                  loaded from layer3.16.bn1.bias           of shape (256,)
2022-11-02 14:57:33,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight                loaded from layer3.16.bn1.weight         of shape (256,)
2022-11-02 14:57:33,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                  loaded from layer3.16.bn2.bias           of shape (256,)
2022-11-02 14:57:33,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight                loaded from layer3.16.bn2.weight         of shape (256,)
2022-11-02 14:57:33,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                  loaded from layer3.16.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight                loaded from layer3.16.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight              loaded from layer3.16.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight              loaded from layer3.16.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight              loaded from layer3.16.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                  loaded from layer3.17.bn1.bias           of shape (256,)
2022-11-02 14:57:33,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight                loaded from layer3.17.bn1.weight         of shape (256,)
2022-11-02 14:57:33,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                  loaded from layer3.17.bn2.bias           of shape (256,)
2022-11-02 14:57:33,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight                loaded from layer3.17.bn2.weight         of shape (256,)
2022-11-02 14:57:33,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                  loaded from layer3.17.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight                loaded from layer3.17.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight              loaded from layer3.17.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight              loaded from layer3.17.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight              loaded from layer3.17.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                  loaded from layer3.18.bn1.bias           of shape (256,)
2022-11-02 14:57:33,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight                loaded from layer3.18.bn1.weight         of shape (256,)
2022-11-02 14:57:33,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                  loaded from layer3.18.bn2.bias           of shape (256,)
2022-11-02 14:57:33,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight                loaded from layer3.18.bn2.weight         of shape (256,)
2022-11-02 14:57:33,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                  loaded from layer3.18.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight                loaded from layer3.18.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight              loaded from layer3.18.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight              loaded from layer3.18.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight              loaded from layer3.18.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                  loaded from layer3.19.bn1.bias           of shape (256,)
2022-11-02 14:57:33,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight                loaded from layer3.19.bn1.weight         of shape (256,)
2022-11-02 14:57:33,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                  loaded from layer3.19.bn2.bias           of shape (256,)
2022-11-02 14:57:33,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight                loaded from layer3.19.bn2.weight         of shape (256,)
2022-11-02 14:57:33,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                  loaded from layer3.19.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight                loaded from layer3.19.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight              loaded from layer3.19.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight              loaded from layer3.19.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight              loaded from layer3.19.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                   loaded from layer3.2.bn1.bias            of shape (256,)
2022-11-02 14:57:33,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                 loaded from layer3.2.bn1.weight          of shape (256,)
2022-11-02 14:57:33,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                   loaded from layer3.2.bn2.bias            of shape (256,)
2022-11-02 14:57:33,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                 loaded from layer3.2.bn2.weight          of shape (256,)
2022-11-02 14:57:33,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                   loaded from layer3.2.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                 loaded from layer3.2.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight               loaded from layer3.2.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight               loaded from layer3.2.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight               loaded from layer3.2.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                  loaded from layer3.20.bn1.bias           of shape (256,)
2022-11-02 14:57:33,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight                loaded from layer3.20.bn1.weight         of shape (256,)
2022-11-02 14:57:33,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                  loaded from layer3.20.bn2.bias           of shape (256,)
2022-11-02 14:57:33,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight                loaded from layer3.20.bn2.weight         of shape (256,)
2022-11-02 14:57:33,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                  loaded from layer3.20.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight                loaded from layer3.20.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight              loaded from layer3.20.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight              loaded from layer3.20.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight              loaded from layer3.20.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                  loaded from layer3.21.bn1.bias           of shape (256,)
2022-11-02 14:57:33,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight                loaded from layer3.21.bn1.weight         of shape (256,)
2022-11-02 14:57:33,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                  loaded from layer3.21.bn2.bias           of shape (256,)
2022-11-02 14:57:33,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight                loaded from layer3.21.bn2.weight         of shape (256,)
2022-11-02 14:57:33,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                  loaded from layer3.21.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight                loaded from layer3.21.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight              loaded from layer3.21.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight              loaded from layer3.21.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight              loaded from layer3.21.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                  loaded from layer3.22.bn1.bias           of shape (256,)
2022-11-02 14:57:33,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight                loaded from layer3.22.bn1.weight         of shape (256,)
2022-11-02 14:57:33,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                  loaded from layer3.22.bn2.bias           of shape (256,)
2022-11-02 14:57:33,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight                loaded from layer3.22.bn2.weight         of shape (256,)
2022-11-02 14:57:33,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                  loaded from layer3.22.bn3.bias           of shape (1024,)
2022-11-02 14:57:33,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight                loaded from layer3.22.bn3.weight         of shape (1024,)
2022-11-02 14:57:33,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight              loaded from layer3.22.conv1.weight       of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight              loaded from layer3.22.conv2.weight       of shape (256, 256, 3, 3)
2022-11-02 14:57:33,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight              loaded from layer3.22.conv3.weight       of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                   loaded from layer3.3.bn1.bias            of shape (256,)
2022-11-02 14:57:33,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                 loaded from layer3.3.bn1.weight          of shape (256,)
2022-11-02 14:57:33,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                   loaded from layer3.3.bn2.bias            of shape (256,)
2022-11-02 14:57:33,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                 loaded from layer3.3.bn2.weight          of shape (256,)
2022-11-02 14:57:33,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                   loaded from layer3.3.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                 loaded from layer3.3.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight               loaded from layer3.3.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight               loaded from layer3.3.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight               loaded from layer3.3.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                   loaded from layer3.4.bn1.bias            of shape (256,)
2022-11-02 14:57:33,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                 loaded from layer3.4.bn1.weight          of shape (256,)
2022-11-02 14:57:33,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                   loaded from layer3.4.bn2.bias            of shape (256,)
2022-11-02 14:57:33,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                 loaded from layer3.4.bn2.weight          of shape (256,)
2022-11-02 14:57:33,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                   loaded from layer3.4.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                 loaded from layer3.4.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight               loaded from layer3.4.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight               loaded from layer3.4.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight               loaded from layer3.4.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                   loaded from layer3.5.bn1.bias            of shape (256,)
2022-11-02 14:57:33,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                 loaded from layer3.5.bn1.weight          of shape (256,)
2022-11-02 14:57:33,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                   loaded from layer3.5.bn2.bias            of shape (256,)
2022-11-02 14:57:33,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                 loaded from layer3.5.bn2.weight          of shape (256,)
2022-11-02 14:57:33,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                   loaded from layer3.5.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                 loaded from layer3.5.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight               loaded from layer3.5.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight               loaded from layer3.5.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight               loaded from layer3.5.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                   loaded from layer3.6.bn1.bias            of shape (256,)
2022-11-02 14:57:33,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                 loaded from layer3.6.bn1.weight          of shape (256,)
2022-11-02 14:57:33,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                   loaded from layer3.6.bn2.bias            of shape (256,)
2022-11-02 14:57:33,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                 loaded from layer3.6.bn2.weight          of shape (256,)
2022-11-02 14:57:33,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                   loaded from layer3.6.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                 loaded from layer3.6.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight               loaded from layer3.6.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight               loaded from layer3.6.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight               loaded from layer3.6.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                   loaded from layer3.7.bn1.bias            of shape (256,)
2022-11-02 14:57:33,888 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                 loaded from layer3.7.bn1.weight          of shape (256,)
2022-11-02 14:57:33,888 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                   loaded from layer3.7.bn2.bias            of shape (256,)
2022-11-02 14:57:33,888 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                 loaded from layer3.7.bn2.weight          of shape (256,)
2022-11-02 14:57:33,888 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                   loaded from layer3.7.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,888 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                 loaded from layer3.7.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,888 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight               loaded from layer3.7.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,889 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight               loaded from layer3.7.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,889 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight               loaded from layer3.7.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,889 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                   loaded from layer3.8.bn1.bias            of shape (256,)
2022-11-02 14:57:33,889 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                 loaded from layer3.8.bn1.weight          of shape (256,)
2022-11-02 14:57:33,889 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                   loaded from layer3.8.bn2.bias            of shape (256,)
2022-11-02 14:57:33,890 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                 loaded from layer3.8.bn2.weight          of shape (256,)
2022-11-02 14:57:33,890 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                   loaded from layer3.8.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,890 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                 loaded from layer3.8.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,890 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight               loaded from layer3.8.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,890 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight               loaded from layer3.8.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight               loaded from layer3.8.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                   loaded from layer3.9.bn1.bias            of shape (256,)
2022-11-02 14:57:33,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                 loaded from layer3.9.bn1.weight          of shape (256,)
2022-11-02 14:57:33,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                   loaded from layer3.9.bn2.bias            of shape (256,)
2022-11-02 14:57:33,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                 loaded from layer3.9.bn2.weight          of shape (256,)
2022-11-02 14:57:33,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                   loaded from layer3.9.bn3.bias            of shape (1024,)
2022-11-02 14:57:33,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                 loaded from layer3.9.bn3.weight          of shape (1024,)
2022-11-02 14:57:33,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight               loaded from layer3.9.conv1.weight        of shape (256, 1024, 1, 1)
2022-11-02 14:57:33,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight               loaded from layer3.9.conv2.weight        of shape (256, 256, 3, 3)
2022-11-02 14:57:33,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight               loaded from layer3.9.conv3.weight        of shape (1024, 256, 1, 1)
2022-11-02 14:57:33,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                   loaded from layer4.0.bn1.bias            of shape (512,)
2022-11-02 14:57:33,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                 loaded from layer4.0.bn1.weight          of shape (512,)
2022-11-02 14:57:33,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                   loaded from layer4.0.bn2.bias            of shape (512,)
2022-11-02 14:57:33,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                 loaded from layer4.0.bn2.weight          of shape (512,)
2022-11-02 14:57:33,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                   loaded from layer4.0.bn3.bias            of shape (2048,)
2022-11-02 14:57:33,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                 loaded from layer4.0.bn3.weight          of shape (2048,)
2022-11-02 14:57:33,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight               loaded from layer4.0.conv1.weight        of shape (512, 1024, 1, 1)
2022-11-02 14:57:33,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight               loaded from layer4.0.conv2.weight        of shape (512, 512, 3, 3)
2022-11-02 14:57:33,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight               loaded from layer4.0.conv3.weight        of shape (2048, 512, 1, 1)
2022-11-02 14:57:33,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight        loaded from layer4.0.downsample.0.weight of shape (2048, 1024, 1, 1)
2022-11-02 14:57:33,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias          loaded from layer4.0.downsample.1.bias   of shape (2048,)
2022-11-02 14:57:33,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight        loaded from layer4.0.downsample.1.weight of shape (2048,)
2022-11-02 14:57:33,894 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                   loaded from layer4.1.bn1.bias            of shape (512,)
2022-11-02 14:57:33,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                 loaded from layer4.1.bn1.weight          of shape (512,)
2022-11-02 14:57:33,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                   loaded from layer4.1.bn2.bias            of shape (512,)
2022-11-02 14:57:33,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                 loaded from layer4.1.bn2.weight          of shape (512,)
2022-11-02 14:57:33,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                   loaded from layer4.1.bn3.bias            of shape (2048,)
2022-11-02 14:57:33,895 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                 loaded from layer4.1.bn3.weight          of shape (2048,)
2022-11-02 14:57:33,896 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight               loaded from layer4.1.conv1.weight        of shape (512, 2048, 1, 1)
2022-11-02 14:57:33,896 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight               loaded from layer4.1.conv2.weight        of shape (512, 512, 3, 3)
2022-11-02 14:57:33,896 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight               loaded from layer4.1.conv3.weight        of shape (2048, 512, 1, 1)
2022-11-02 14:57:33,896 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                   loaded from layer4.2.bn1.bias            of shape (512,)
2022-11-02 14:57:33,896 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                 loaded from layer4.2.bn1.weight          of shape (512,)
2022-11-02 14:57:33,896 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                   loaded from layer4.2.bn2.bias            of shape (512,)
2022-11-02 14:57:33,897 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                 loaded from layer4.2.bn2.weight          of shape (512,)
2022-11-02 14:57:33,897 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                   loaded from layer4.2.bn3.bias            of shape (2048,)
2022-11-02 14:57:33,897 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                 loaded from layer4.2.bn3.weight          of shape (2048,)
2022-11-02 14:57:33,897 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight               loaded from layer4.2.conv1.weight        of shape (512, 2048, 1, 1)
2022-11-02 14:57:33,897 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight               loaded from layer4.2.conv2.weight        of shape (512, 512, 3, 3)
2022-11-02 14:57:33,898 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight               loaded from layer4.2.conv3.weight        of shape (2048, 512, 1, 1)
2022-11-02 14:57:33,898 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                       loaded from bn1.bias                     of shape (64,)
2022-11-02 14:57:33,898 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                     loaded from bn1.weight                   of shape (64,)
2022-11-02 14:57:33,898 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                   loaded from conv1.weight                 of shape (64, 3, 7, 7)
2022-11-02 14:57:33,985 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:57:34,262 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into runs/cat_dog_coco/labels.json
2022-11-02 14:57:34,399 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 14:57:34,405 maskrcnn_benchmark.trainer INFO: Start training
2022-11-02 14:58:19,532 maskrcnn_benchmark.trainer INFO: eta: 0:06:46  iter: 20  loss: 1.0378 (1.6699)  loss_classifier: 0.1906 (0.2481)  loss_box_reg: 0.1296 (0.1211)  loss_mask: 0.6828 (1.0630)  loss_objectness: 0.0922 (0.2270)  loss_rpn_box_reg: 0.0098 (0.0108)  time: 2.5006 (2.2561)  data: 0.0094 (0.0299)  lr: 0.003600  max mem: 3404
2022-11-02 14:59:05,141 maskrcnn_benchmark.trainer INFO: eta: 0:06:02  iter: 40  loss: 0.7764 (1.2284)  loss_classifier: 0.1326 (0.1931)  loss_box_reg: 0.1211 (0.1254)  loss_mask: 0.4577 (0.7708)  loss_objectness: 0.0267 (0.1285)  loss_rpn_box_reg: 0.0107 (0.0107)  time: 2.5560 (2.2683)  data: 0.0104 (0.0201)  lr: 0.003867  max mem: 3413
2022-11-02 14:59:51,166 maskrcnn_benchmark.trainer INFO: eta: 0:05:19  iter: 60  loss: 0.6474 (1.0365)  loss_classifier: 0.1185 (0.1696)  loss_box_reg: 0.1246 (0.1260)  loss_mask: 0.3568 (0.6361)  loss_objectness: 0.0205 (0.0941)  loss_rpn_box_reg: 0.0079 (0.0106)  time: 2.5734 (2.2793)  data: 0.0107 (0.0172)  lr: 0.004133  max mem: 3437
2022-11-02 15:00:37,388 maskrcnn_benchmark.trainer INFO: eta: 0:04:34  iter: 80  loss: 0.5341 (0.9162)  loss_classifier: 0.1079 (0.1553)  loss_box_reg: 0.1246 (0.1263)  loss_mask: 0.2721 (0.5474)  loss_objectness: 0.0211 (0.0767)  loss_rpn_box_reg: 0.0100 (0.0105)  time: 2.5475 (2.2872)  data: 0.0101 (0.0154)  lr: 0.004400  max mem: 3437
2022-11-02 15:01:23,412 maskrcnn_benchmark.trainer INFO: eta: 0:03:49  iter: 100  loss: 0.4727 (0.8306)  loss_classifier: 0.0984 (0.1442)  loss_box_reg: 0.1231 (0.1254)  loss_mask: 0.2277 (0.4845)  loss_objectness: 0.0216 (0.0661)  loss_rpn_box_reg: 0.0084 (0.0103)  time: 2.5303 (2.2900)  data: 0.0089 (0.0141)  lr: 0.000467  max mem: 3521
2022-11-02 15:01:23,413 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 15:01:23,419 maskrcnn_benchmark.inference INFO: Start evaluation on [Validation] dataset(14 images).
2022-11-02 15:01:28,001 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.582096 (0.3272925445011684 s / img per device, on 1 devices)
2022-11-02 15:01:28,002 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.203308 (0.30023627621786936 s / img per device, on 1 devices)
2022-11-02 15:01:28,002 maskrcnn_benchmark.inference INFO: Preparing results for COCO format
2022-11-02 15:01:28,002 maskrcnn_benchmark.inference INFO: Preparing bbox results
2022-11-02 15:01:28,008 maskrcnn_benchmark.inference INFO: Preparing segm results
2022-11-02 15:01:28,663 maskrcnn_benchmark.inference INFO: Evaluating predictions
2022-11-02 15:01:28,872 maskrcnn_benchmark.inference INFO: 
Task: bbox
AP, AP50, AP75, APs, APm, APl
0.2705, 0.6834, 0.1503, -1.0000, 0.0000, 0.2784
Task: segm
AP, AP50, AP75, APs, APm, APl
0.3792, 0.6731, 0.3624, -1.0000, 0.0375, 0.4225

2022-11-02 15:01:33,326 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:03:49  iter: 100  loss: 0.4651 (0.4661)  loss_classifier: 0.0910 (0.0956)  loss_box_reg: 0.1049 (0.1136)  loss_mask: 0.2288 (0.2251)  loss_objectness: 0.0203 (0.0231)  loss_rpn_box_reg: 0.0088 (0.0087)  lr: 0.000467  max mem: 3521
2022-11-02 15:02:19,135 maskrcnn_benchmark.trainer INFO: eta: 0:03:09  iter: 120  loss: 0.4264 (0.7649)  loss_classifier: 0.0881 (0.1355)  loss_box_reg: 0.1094 (0.1225)  loss_mask: 0.2079 (0.4380)  loss_objectness: 0.0222 (0.0588)  loss_rpn_box_reg: 0.0065 (0.0100)  time: 2.5545 (2.3727)  data: 0.0099 (0.0961)  lr: 0.000493  max mem: 3550
2022-11-02 15:03:05,336 maskrcnn_benchmark.trainer INFO: eta: 0:02:21  iter: 140  loss: 0.4071 (0.7159)  loss_classifier: 0.0922 (0.1288)  loss_box_reg: 0.1013 (0.1196)  loss_mask: 0.1973 (0.4042)  loss_objectness: 0.0209 (0.0536)  loss_rpn_box_reg: 0.0069 (0.0098)  time: 2.5588 (2.3638)  data: 0.0102 (0.0838)  lr: 0.000520  max mem: 3550
2022-11-02 15:03:51,554 maskrcnn_benchmark.trainer INFO: eta: 0:01:34  iter: 160  loss: 0.4073 (0.6781)  loss_classifier: 0.0900 (0.1240)  loss_box_reg: 0.0992 (0.1169)  loss_mask: 0.1974 (0.3779)  loss_objectness: 0.0204 (0.0497)  loss_rpn_box_reg: 0.0072 (0.0096)  time: 2.5500 (2.3572)  data: 0.0109 (0.0746)  lr: 0.000547  max mem: 3567
2022-11-02 15:04:37,971 maskrcnn_benchmark.trainer INFO: eta: 0:00:47  iter: 180  loss: 0.3952 (0.6476)  loss_classifier: 0.0836 (0.1199)  loss_box_reg: 0.0911 (0.1143)  loss_mask: 0.1922 (0.3574)  loss_objectness: 0.0196 (0.0466)  loss_rpn_box_reg: 0.0068 (0.0095)  time: 2.5734 (2.3531)  data: 0.0107 (0.0675)  lr: 0.000573  max mem: 3567
2022-11-02 15:05:24,510 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 200  loss: 0.4069 (0.6225)  loss_classifier: 0.0838 (0.1165)  loss_box_reg: 0.0917 (0.1119)  loss_mask: 0.1846 (0.3407)  loss_objectness: 0.0207 (0.0441)  loss_rpn_box_reg: 0.0068 (0.0093)  time: 2.5799 (2.3505)  data: 0.0095 (0.0617)  lr: 0.000060  max mem: 3579
2022-11-02 15:05:24,510 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 15:05:24,515 maskrcnn_benchmark.inference INFO: Start evaluation on [Validation] dataset(14 images).
2022-11-02 15:05:29,032 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.516776 (0.3226268802370344 s / img per device, on 1 devices)
2022-11-02 15:05:29,033 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.163779 (0.2974128041948591 s / img per device, on 1 devices)
2022-11-02 15:05:29,033 maskrcnn_benchmark.inference INFO: Preparing results for COCO format
2022-11-02 15:05:29,033 maskrcnn_benchmark.inference INFO: Preparing bbox results
2022-11-02 15:05:29,038 maskrcnn_benchmark.inference INFO: Preparing segm results
2022-11-02 15:05:29,574 maskrcnn_benchmark.inference INFO: Evaluating predictions
2022-11-02 15:05:29,750 maskrcnn_benchmark.inference INFO: 
Task: bbox
AP, AP50, AP75, APs, APm, APl
0.3716, 0.8263, 0.2975, -1.0000, 0.0000, 0.3833
Task: segm
AP, AP50, AP75, APs, APm, APl
0.5150, 0.8198, 0.5067, -1.0000, 0.0429, 0.5444

2022-11-02 15:05:34,182 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:00:00  iter: 200  loss: 0.3960 (0.4012)  loss_classifier: 0.0764 (0.0865)  loss_box_reg: 0.0866 (0.0947)  loss_mask: 0.1939 (0.1897)  loss_objectness: 0.0205 (0.0226)  loss_rpn_box_reg: 0.0077 (0.0077)  lr: 0.000060  max mem: 3579
2022-11-02 15:05:34,316 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to runs/cat_dog_coco/model_final.pth
2022-11-02 15:05:43,826 maskrcnn_benchmark.trainer INFO: Total training time: 0:08:09.416285 (2.4471 s / it)
2022-11-02 15:05:44,278 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2022-11-02 15:05:44,286 maskrcnn_benchmark.inference INFO: Start evaluation on coco_cat_dog_val dataset(14 images).
2022-11-02 15:05:48,538 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.252209 (0.3037292446408953 s / img per device, on 1 devices)
2022-11-02 15:05:48,539 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:03.933724 (0.2809803145272391 s / img per device, on 1 devices)
2022-11-02 15:05:48,562 maskrcnn_benchmark.inference INFO: Preparing results for COCO format
2022-11-02 15:05:48,562 maskrcnn_benchmark.inference INFO: Preparing bbox results
2022-11-02 15:05:48,568 maskrcnn_benchmark.inference INFO: Preparing segm results
2022-11-02 15:05:49,072 maskrcnn_benchmark.inference INFO: Evaluating predictions
2022-11-02 15:05:49,273 maskrcnn_benchmark.inference INFO: 
Task: bbox
AP, AP50, AP75, APs, APm, APl
0.3716, 0.8263, 0.2975, -1.0000, 0.0000, 0.3833
Task: segm
AP, AP50, AP75, APs, APm, APl
0.5150, 0.8198, 0.5067, -1.0000, 0.0429, 0.5444

